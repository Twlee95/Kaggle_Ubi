{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## import library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gc\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow import keras\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>time_id</th>\n",
       "      <th>investment_id</th>\n",
       "      <th>target</th>\n",
       "      <th>f_0</th>\n",
       "      <th>f_1</th>\n",
       "      <th>f_2</th>\n",
       "      <th>f_3</th>\n",
       "      <th>f_4</th>\n",
       "      <th>f_5</th>\n",
       "      <th>f_6</th>\n",
       "      <th>...</th>\n",
       "      <th>f_290</th>\n",
       "      <th>f_291</th>\n",
       "      <th>f_292</th>\n",
       "      <th>f_293</th>\n",
       "      <th>f_294</th>\n",
       "      <th>f_295</th>\n",
       "      <th>f_296</th>\n",
       "      <th>f_297</th>\n",
       "      <th>f_298</th>\n",
       "      <th>f_299</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.300781</td>\n",
       "      <td>0.932573</td>\n",
       "      <td>0.113691</td>\n",
       "      <td>-0.402206</td>\n",
       "      <td>0.378386</td>\n",
       "      <td>-0.203938</td>\n",
       "      <td>-0.413469</td>\n",
       "      <td>0.965623</td>\n",
       "      <td>...</td>\n",
       "      <td>0.366028</td>\n",
       "      <td>-1.095620</td>\n",
       "      <td>0.200075</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.086764</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-1.044826</td>\n",
       "      <td>-0.287605</td>\n",
       "      <td>0.321566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>-0.231079</td>\n",
       "      <td>0.810802</td>\n",
       "      <td>-0.514115</td>\n",
       "      <td>0.742368</td>\n",
       "      <td>-0.616673</td>\n",
       "      <td>-0.194255</td>\n",
       "      <td>1.771210</td>\n",
       "      <td>1.428127</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.154193</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.734579</td>\n",
       "      <td>0.819155</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.387617</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.929529</td>\n",
       "      <td>-0.974060</td>\n",
       "      <td>-0.343624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.568848</td>\n",
       "      <td>0.393974</td>\n",
       "      <td>0.615937</td>\n",
       "      <td>0.567806</td>\n",
       "      <td>-0.607963</td>\n",
       "      <td>0.068883</td>\n",
       "      <td>-1.083155</td>\n",
       "      <td>0.979656</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.138020</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.551904</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>-1.060166</td>\n",
       "      <td>-0.219097</td>\n",
       "      <td>-1.087009</td>\n",
       "      <td>-0.612428</td>\n",
       "      <td>-0.113944</td>\n",
       "      <td>0.243608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>-1.064453</td>\n",
       "      <td>-2.343535</td>\n",
       "      <td>-0.011870</td>\n",
       "      <td>1.874606</td>\n",
       "      <td>-0.606346</td>\n",
       "      <td>-0.586827</td>\n",
       "      <td>-0.815737</td>\n",
       "      <td>0.778096</td>\n",
       "      <td>...</td>\n",
       "      <td>0.382201</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.266359</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.609113</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>-0.783423</td>\n",
       "      <td>1.151730</td>\n",
       "      <td>-0.773309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>-0.531738</td>\n",
       "      <td>0.842057</td>\n",
       "      <td>-0.262993</td>\n",
       "      <td>2.330030</td>\n",
       "      <td>-0.583422</td>\n",
       "      <td>-0.618392</td>\n",
       "      <td>-0.742814</td>\n",
       "      <td>-0.946789</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.170365</td>\n",
       "      <td>0.912726</td>\n",
       "      <td>-0.741355</td>\n",
       "      <td>-1.220772</td>\n",
       "      <td>0.941183</td>\n",
       "      <td>-0.588445</td>\n",
       "      <td>0.104928</td>\n",
       "      <td>0.753279</td>\n",
       "      <td>1.345611</td>\n",
       "      <td>-0.737624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 303 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   time_id  investment_id    target       f_0       f_1       f_2       f_3  \\\n",
       "0      0.0            1.0 -0.300781  0.932573  0.113691 -0.402206  0.378386   \n",
       "1      0.0            2.0 -0.231079  0.810802 -0.514115  0.742368 -0.616673   \n",
       "2      0.0            6.0  0.568848  0.393974  0.615937  0.567806 -0.607963   \n",
       "3      0.0            7.0 -1.064453 -2.343535 -0.011870  1.874606 -0.606346   \n",
       "4      0.0            8.0 -0.531738  0.842057 -0.262993  2.330030 -0.583422   \n",
       "\n",
       "        f_4       f_5       f_6  ...     f_290     f_291     f_292     f_293  \\\n",
       "0 -0.203938 -0.413469  0.965623  ...  0.366028 -1.095620  0.200075  0.819155   \n",
       "1 -0.194255  1.771210  1.428127  ... -0.154193  0.912726 -0.734579  0.819155   \n",
       "2  0.068883 -1.083155  0.979656  ... -0.138020  0.912726 -0.551904 -1.220772   \n",
       "3 -0.586827 -0.815737  0.778096  ...  0.382201  0.912726 -0.266359 -1.220772   \n",
       "4 -0.618392 -0.742814 -0.946789  ... -0.170365  0.912726 -0.741355 -1.220772   \n",
       "\n",
       "      f_294     f_295     f_296     f_297     f_298     f_299  \n",
       "0  0.941183 -0.086764 -1.087009 -1.044826 -0.287605  0.321566  \n",
       "1  0.941183 -0.387617 -1.087009 -0.929529 -0.974060 -0.343624  \n",
       "2 -1.060166 -0.219097 -1.087009 -0.612428 -0.113944  0.243608  \n",
       "3  0.941183 -0.609113  0.104928 -0.783423  1.151730 -0.773309  \n",
       "4  0.941183 -0.588445  0.104928  0.753279  1.345611 -0.737624  \n",
       "\n",
       "[5 rows x 303 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_features = 300\n",
    "features = [f'f_{i}' for i in range(n_features)]\n",
    "train = pd.read_pickle(r\"C:\\Users\\USER\\Desktop\\ubiquant-market-prediction\\train.pkl\")\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0             1.0\n",
      "1             2.0\n",
      "2             6.0\n",
      "3             7.0\n",
      "4             8.0\n",
      "            ...  \n",
      "3141405    3768.0\n",
      "3141406    3768.0\n",
      "3141407    3770.0\n",
      "3141408    3772.0\n",
      "3141409    3772.0\n",
      "Name: investment_id, Length: 3141410, dtype: float16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0   -0.300781\n",
       "1   -0.231079\n",
       "2    0.568848\n",
       "3   -1.064453\n",
       "4   -0.531738\n",
       "Name: target, dtype: float16"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "investment_id = train.pop(\"investment_id\")\n",
    "investment_id.head()\n",
    "\n",
    "print(investment_id)\n",
    "\n",
    "_ = train.pop(\"time_id\")\n",
    "\n",
    "y = train.pop(\"target\")\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## custom loss function (ccc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def corr_based_loss(pred_y, true_y):\n",
    "    pred_mean = tf.math.reduced_mean(pred_y)\n",
    "    true_mean = tf.math.reduced_mean(true_y)\n",
    "\n",
    "    pred_std = tf.math.reduced_std(pred_y)\n",
    "    true_std = tf.math.reduced_std(true_y)\n",
    "\n",
    "    corr_ = tf.math.reduced_sum((pred_y-pred_mean)*(true_y-true_mean))/(len(pred_y)-1)\n",
    "    ccc = (2*corr_*pred_std*true_std)/(pred_std**2+true_std**2+(pred_mean-true_mean)**2)\n",
    "    return ccc\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a IntegerLookup layer for investment_id input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2789\n"
     ]
    }
   ],
   "source": [
    "investment_ids = list(investment_id.unique())\n",
    "investment_id_size = len(investment_ids) + 1\n",
    "print(investment_id_size)\n",
    "investment_id_lookup_layer = layers.IntegerLookup(max_tokens=investment_id_size)\n",
    "## integerlookup은 \n",
    "investment_id_lookup_layer.adapt(pd.DataFrame({\"investment_ids\":investment_ids})) \n",
    "## 일부 전처리 레이어는 훈련데이터의 셈플을 기반으로 계산해야하는 내부 상태가 있음.\n",
    "## 이러한 전처리 레이어는 '훈련불가능'하기 때문에 훈련중 설정이 되지않음. -> 훈련전에 설정해야함\n",
    "## 이 단계를 적응(adaptation)이라고 함.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def preprocess(X, y):\n",
    "    return X, y\n",
    "def make_dataset(feature, investment_id, y, batch_size=1024, mode=\"train\"):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature), y))\n",
    "    ds = ds.map(preprocess)\n",
    "    if mode == \"train\":\n",
    "        ds = ds.shuffle(4096) ## 완벽한 셔플링을 위해서는 셔플링의 크기와 버퍼의 크기가 같아야함\n",
    "    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model():\n",
    "    investment_id_inputs = tf.keras.Input((1, ), dtype=tf.uint16)\n",
    "    features_inputs = tf.keras.Input((300, ), dtype=tf.float16)\n",
    "    \n",
    "    ## Embedding()을 사용하기 위해서는 입력 될 각 단어들은 모두 정수 인덱싱이 되어 있어야 합니다.\n",
    "    # this code uses variables embedding method because one-hot encoding has many computational costs \n",
    "\n",
    "    investment_id_x = investment_id_lookup_layer(investment_id_inputs)\n",
    "    investment_id_x = layers.Embedding(investment_id_size, 32, input_length=1)(investment_id_x)\n",
    "    investment_id_x = layers.Reshape((-1, ))(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    investment_id_x = layers.Dense(64, activation='swish')(investment_id_x)\n",
    "    \n",
    "    feature_x = layers.Dense(256, activation='swish')(features_inputs)\n",
    "    feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "    feature_x = layers.Dense(256, activation='swish')(feature_x)\n",
    "    \n",
    "    x = layers.Concatenate(axis=1)([investment_id_x, feature_x])\n",
    "    x = layers.Dense(512, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dense(128, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    x = layers.Dense(32, activation='swish', kernel_regularizer=\"l2\")(x)\n",
    "    output = layers.Dense(1)(x)\n",
    "    rmse = keras.metrics.RootMeanSquaredError(name=\"rmse\")\n",
    "    corr_loss = \n",
    "    model = tf.keras.Model(inputs=[investment_id_inputs, features_inputs], outputs=[output])\n",
    "    model.compile(optimizer=tf.optimizers.Adam(0.001), loss='mse', metrics=['mse', \"mae\", \"mape\", rmse])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_17 (InputLayer)          [(None, 1)]          0           []                               \n",
      "                                                                                                  \n",
      " integer_lookup (IntegerLookup)  (None, 1)           0           ['input_17[0][0]']               \n",
      "                                                                                                  \n",
      " embedding_7 (Embedding)        (None, 1, 32)        89248       ['integer_lookup[7][0]']         \n",
      "                                                                                                  \n",
      " reshape_7 (Reshape)            (None, 32)           0           ['embedding_7[0][0]']            \n",
      "                                                                                                  \n",
      " input_18 (InputLayer)          [(None, 300)]        0           []                               \n",
      "                                                                                                  \n",
      " dense_70 (Dense)               (None, 64)           2112        ['reshape_7[0][0]']              \n",
      "                                                                                                  \n",
      " dense_73 (Dense)               (None, 256)          77056       ['input_18[0][0]']               \n",
      "                                                                                                  \n",
      " dense_71 (Dense)               (None, 64)           4160        ['dense_70[0][0]']               \n",
      "                                                                                                  \n",
      " dense_74 (Dense)               (None, 256)          65792       ['dense_73[0][0]']               \n",
      "                                                                                                  \n",
      " dense_72 (Dense)               (None, 64)           4160        ['dense_71[0][0]']               \n",
      "                                                                                                  \n",
      " dense_75 (Dense)               (None, 256)          65792       ['dense_74[0][0]']               \n",
      "                                                                                                  \n",
      " concatenate_7 (Concatenate)    (None, 320)          0           ['dense_72[0][0]',               \n",
      "                                                                  'dense_75[0][0]']               \n",
      "                                                                                                  \n",
      " dense_76 (Dense)               (None, 512)          164352      ['concatenate_7[0][0]']          \n",
      "                                                                                                  \n",
      " dense_77 (Dense)               (None, 128)          65664       ['dense_76[0][0]']               \n",
      "                                                                                                  \n",
      " dense_78 (Dense)               (None, 32)           4128        ['dense_77[0][0]']               \n",
      "                                                                                                  \n",
      " dense_79 (Dense)               (None, 1)            33          ['dense_78[0][0]']               \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 542,497\n",
      "Trainable params: 542,497\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "('You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) ', 'for plot_model/model_to_dot to work.')\n"
     ]
    }
   ],
   "source": [
    "model = get_model()\n",
    "model.summary()\n",
    "keras.utils.plot_model(model, show_shapes=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\USER\\Anaconda3\\envs\\tw_tf\\lib\\site-packages\\sklearn\\model_selection\\_split.py:676: UserWarning: The least populated class in y has only 2 members, which is less than n_splits=5.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train : \t               f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
      "0        0.932573  0.113691 -0.402206  0.378386 -0.203938 -0.413469  0.965623   \n",
      "1        0.810802 -0.514115  0.742368 -0.616673 -0.194255  1.771210  1.428127   \n",
      "2        0.393974  0.615937  0.567806 -0.607963  0.068883 -1.083155  0.979656   \n",
      "3       -2.343535 -0.011870  1.874606 -0.606346 -0.586827 -0.815737  0.778096   \n",
      "6       -1.863797  0.113691  1.573864 -0.598433 -0.569936  0.398784  0.054528   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "3141404  0.892171 -1.760851  0.135189 -0.405799 -0.214687  0.142001  1.134768   \n",
      "3141405  0.093530 -0.720275 -0.345497 -0.438781 -0.166972 -0.437182  1.475746   \n",
      "3141406 -1.344935 -0.199987 -0.107702 -0.454677 -0.221914 -0.141174 -1.498235   \n",
      "3141408 -2.565332  0.320301  0.076600  1.380182 -0.155366 -0.689000  0.381069   \n",
      "3141409 -0.089557  0.190229 -0.548256  0.151205  0.079773  0.447962  1.014983   \n",
      "\n",
      "              f_7       f_8       f_9  ...     f_290     f_291     f_292  \\\n",
      "0        1.230508  0.114809 -2.012777  ...  0.366028 -1.095620  0.200075   \n",
      "1        1.134144  0.114809 -0.219201  ... -0.154193  0.912726 -0.734579   \n",
      "2       -1.125681  0.114809 -1.035376  ... -0.138020  0.912726 -0.551904   \n",
      "3        0.298990  0.114809 -1.176410  ...  0.382201  0.912726 -0.266359   \n",
      "6        0.724549  0.114809  0.318106  ...  0.821560  0.912726  0.476309   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "3141404 -0.517340  0.056425  1.097691  ...  0.639348 -1.232434  0.311625   \n",
      "3141405  1.284423  0.056425 -1.433681  ... -0.285908 -1.232434 -0.660579   \n",
      "3141406  1.373834  0.056425 -1.211572  ...  0.184517 -1.232434 -0.670493   \n",
      "3141408 -1.324759  0.056425 -1.111730  ... -0.756332 -1.232434  0.133074   \n",
      "3141409 -1.324759  0.056425 -1.952123  ... -0.317095  0.811402  3.271590   \n",
      "\n",
      "            f_293     f_294     f_295     f_296     f_297     f_298     f_299  \n",
      "0        0.819155  0.941183 -0.086764 -1.087009 -1.044826 -0.287605  0.321566  \n",
      "1        0.819155  0.941183 -0.387617 -1.087009 -0.929529 -0.974060 -0.343624  \n",
      "2       -1.220772 -1.060166 -0.219097 -1.087009 -0.612428 -0.113944  0.243608  \n",
      "3       -1.220772  0.941183 -0.609113  0.104928 -0.783423  1.151730 -0.773309  \n",
      "6       -1.220772  0.941183 -0.434315  1.296864  0.171329  1.051288 -0.745335  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "3141404  0.875537  0.421628 -0.332911  1.363181 -0.075892 -1.420459 -0.521622  \n",
      "3141405  0.875537  0.421628 -0.428097 -0.075548 -0.533092 -0.193732 -0.581394  \n",
      "3141406  0.875537  0.421628 -0.729949 -1.514277  0.013145 -0.890270 -0.589705  \n",
      "3141408 -1.142157  0.421628 -0.375288 -1.514277 -0.973762  0.608647 -0.372040  \n",
      "3141409  0.875537  0.421628 -0.170709  1.363181 -0.563314  0.669586  0.456400  \n",
      "\n",
      "[2513128 rows x 300 columns]\n",
      "X_val : \t               f_0       f_1       f_2       f_3       f_4       f_5       f_6  \\\n",
      "4        0.842057 -0.262993  2.330030 -0.583422 -0.618392 -0.742814 -0.946789   \n",
      "5        0.608855  1.369305 -0.761515  0.865860 -0.359269 -1.835762  1.384409   \n",
      "10       0.686414 -0.514115 -1.465751  0.505034  3.336757 -1.988232 -0.444304   \n",
      "11       0.081737  1.745989 -1.218067  1.380061 -0.036835 -1.552630  0.991577   \n",
      "15       0.000000  3.503847  0.776656 -0.576955  0.398469  2.639607 -0.920601   \n",
      "...           ...       ...       ...       ...       ...       ...       ...   \n",
      "3141388  0.447173 -0.460131  0.197822 -0.432405 -0.029318 -1.600465 -0.566944   \n",
      "3141393 -1.300545  1.490949 -0.621157  0.276278 -0.140592  0.927713 -1.415919   \n",
      "3141394 -0.089364 -0.069915  1.411002 -0.405366  0.152336 -0.186410 -1.812565   \n",
      "3141399  0.829150 -0.980419  0.137483 -0.448415 -0.222940 -0.177434  0.241221   \n",
      "3141407  0.979489 -1.110491  1.006980 -0.467307 -0.159549  1.355671  0.150812   \n",
      "\n",
      "              f_7       f_8       f_9  ...     f_290     f_291     f_292  \\\n",
      "4        1.230508  0.114809 -0.005858  ... -0.170365  0.912726 -0.741355   \n",
      "5       -1.789227  0.114809 -1.900184  ...  0.333684 -1.095620 -0.335999   \n",
      "10      -1.789227  0.114809  0.801366  ... -0.658241  0.912726 -1.137827   \n",
      "11      -0.710902  0.114809 -0.501794  ...  0.349856 -1.095620  0.000378   \n",
      "15       0.602612  0.114809  0.344168  ... -0.105676 -1.095620  2.194626   \n",
      "...           ...       ...       ...  ...       ...       ...       ...   \n",
      "3141388 -0.181319  0.056425 -1.187807  ... -0.756332  0.811402 -0.747365   \n",
      "3141393 -1.926414  0.056425 -1.058461  ... -0.756332  0.811402  0.004035   \n",
      "3141394  0.476270  0.056425  0.240736  ...  0.639348  0.811402 -0.350773   \n",
      "3141399  1.427723  0.056425 -1.743312  ...  0.184517 -1.232434  0.119316   \n",
      "3141407 -0.088923  0.056425  0.996380  ... -0.756332 -1.232434  0.820784   \n",
      "\n",
      "            f_293     f_294     f_295     f_296     f_297     f_298     f_299  \n",
      "4       -1.220772  0.941183 -0.588445  0.104928  0.753279  1.345611 -0.737624  \n",
      "5        0.819155 -1.060166 -0.343812 -1.087009  0.077862  0.142943 -0.055550  \n",
      "10       0.819155  0.941183  1.132590  0.104928  1.174890  1.085646  2.405461  \n",
      "11       0.819155 -1.060166  0.210915 -1.087009 -0.367434  0.537452  0.243616  \n",
      "15       0.819155 -1.477153  0.653271  1.296864 -0.247746  0.000000  1.422416  \n",
      "...           ...       ...       ...       ...       ...       ...       ...  \n",
      "3141388 -1.142157  0.421628 -0.272396  1.363181  0.014085  0.710105 -0.229014  \n",
      "3141393  0.875537  0.421628 -0.304018  1.363181 -0.852834  0.119049 -0.259806  \n",
      "3141394  0.875537  0.421628  0.575612  1.363181 -0.089519  1.105934  0.181167  \n",
      "3141399 -1.142157  0.421628 -0.704748 -0.075548 -0.091505 -1.000041 -0.641396  \n",
      "3141407 -1.142157  0.421628 -0.363329  1.363181 -0.079106 -1.580124 -0.297625  \n",
      "\n",
      "[628282 rows x 300 columns]\n",
      "investment_id : \t 0             1.0\n",
      "1             2.0\n",
      "2             6.0\n",
      "3             7.0\n",
      "4             8.0\n",
      "            ...  \n",
      "3141405    3768.0\n",
      "3141406    3768.0\n",
      "3141407    3770.0\n",
      "3141408    3772.0\n",
      "3141409    3772.0\n",
      "Name: investment_id, Length: 3141410, dtype: float16\n",
      "investment_id_train : \t 0             1.0\n",
      "1             2.0\n",
      "2             6.0\n",
      "3             7.0\n",
      "6            10.0\n",
      "            ...  \n",
      "3141404    3766.0\n",
      "3141405    3768.0\n",
      "3141406    3768.0\n",
      "3141408    3772.0\n",
      "3141409    3772.0\n",
      "Name: investment_id, Length: 2513128, dtype: float16\n",
      "y_train : \t 0         -0.300781\n",
      "1         -0.231079\n",
      "2          0.568848\n",
      "3         -1.064453\n",
      "6         -0.260742\n",
      "             ...   \n",
      "3141404    0.351807\n",
      "3141405    0.033600\n",
      "3141406   -0.223267\n",
      "3141408    0.009598\n",
      "3141409    1.211914\n",
      "Name: target, Length: 2513128, dtype: float16\n",
      "y_val : \t 4         -0.531738\n",
      "5          1.505859\n",
      "10        -0.130493\n",
      "11         0.365479\n",
      "15         0.171631\n",
      "             ...   \n",
      "3141388   -0.117432\n",
      "3141393    0.164307\n",
      "3141394    0.127563\n",
      "3141399   -0.167969\n",
      "3141407   -0.559570\n",
      "Name: target, Length: 628282, dtype: float16\n",
      "investment_id_val : \t 4             8.0\n",
      "5             9.0\n",
      "10           16.0\n",
      "11           17.0\n",
      "15           24.0\n",
      "            ...  \n",
      "3141388    3748.0\n",
      "3141393    3754.0\n",
      "3141394    3756.0\n",
      "3141399    3760.0\n",
      "3141407    3770.0\n",
      "Name: investment_id, Length: 628282, dtype: float16\n",
      "Epoch 1/30\n",
      " 651/2455 [======>.......................] - ETA: 55s - loss: 1.1253 - mse: 0.8387 - mae: 0.6455 - mape: 89110.4141 - rmse: 0.9158"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "kfold = StratifiedKFold(5, shuffle=True, random_state=42)\n",
    "models = []\n",
    "for index, (train_indices, valid_indices) in enumerate(kfold.split(train, investment_id)):\n",
    "    ## \n",
    "    X_train, X_val = train.iloc[train_indices], train.iloc[valid_indices]\n",
    "    print(\"X_train : \\n {}\".format(X_train))\n",
    "    print(\"X_val : \\n {}\".format(X_val))\n",
    "    print(\"investment_id : \\n {}\".format(investment_id))\n",
    "    investment_id_train = investment_id[train_indices]\n",
    "    print(\"investment_id_train : \\n {}\".format(investment_id_train))\n",
    "\n",
    "    y_train, y_val = y.iloc[train_indices], y.iloc[valid_indices]\n",
    "    print(\"y_train : \\n {}\".format(y_train))\n",
    "    print(\"y_val : \\n {}\".format(y_val))\n",
    " \n",
    "    investment_id_val = investment_id[valid_indices]\n",
    "    print(\"investment_id_val : \\n {}\".format(investment_id_val))\n",
    "\n",
    "    train_ds = make_dataset(X_train, investment_id_train, y_train)\n",
    "    valid_ds = make_dataset(X_val, investment_id_val, y_val, mode=\"valid\")\n",
    "    \n",
    "    model = get_model()\n",
    "    checkpoint = keras.callbacks.ModelCheckpoint(f\"model_{index}\", save_best_only=True)\n",
    "    early_stop = keras.callbacks.EarlyStopping(patience=10)\n",
    "    history = model.fit(train_ds, epochs=30, validation_data=valid_ds, callbacks=[checkpoint, early_stop])\n",
    "    \n",
    "    model = keras.models.load_model(f\"model_{index}\") ## this notebook uses k-fold cross validation and the number of this model is 5\n",
    "    models.append(model)\n",
    "    \n",
    "    pearson_score = stats.pearsonr(model.predict(valid_ds).ravel(), y_val.values)[0]\n",
    "    print('Pearson:', pearson_score)\n",
    "    pd.DataFrame(history.history, columns=[\"mse\", \"val_mse\"]).plot()\n",
    "    plt.title(\"MSE\")\n",
    "    plt.show()\n",
    "    pd.DataFrame(history.history, columns=[\"mae\", \"val_mae\"]).plot()\n",
    "    plt.title(\"MAE\")\n",
    "    plt.show()\n",
    "    pd.DataFrame(history.history, columns=[\"rmse\", \"val_rmse\"]).plot()\n",
    "    plt.title(\"RMSE\")\n",
    "    plt.show()\n",
    "    del investment_id_train\n",
    "    del investment_id_val\n",
    "    del X_train\n",
    "    del X_val\n",
    "    del y_train\n",
    "    del y_val\n",
    "    del train_ds\n",
    "    del valid_ds\n",
    "    gc.collect()\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mRunning cells with 'Python 3.7.11 64-bit ('py37_taewon_tf': conda)' requires ipykernel package.\n",
      "Run the following command to install 'ipykernel' into the Python environment. \n",
      "Command: 'conda install -n py37_taewon_tf ipykernel --update-deps --force-reinstall'"
     ]
    }
   ],
   "source": [
    "def preprocess_test(investment_id, feature):\n",
    "    return (investment_id, feature), 0\n",
    "def make_test_dataset(feature, investment_id, batch_size=1024):\n",
    "    ds = tf.data.Dataset.from_tensor_slices(((investment_id, feature)))\n",
    "    ds = ds.map(preprocess_test)\n",
    "    ds = ds.batch(batch_size).cache().prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return ds\n",
    "def inference(models, ds):\n",
    "    y_preds = []\n",
    "    for model in models:\n",
    "        y_pred = model.predict(ds)\n",
    "        y_preds.append(y_pred)\n",
    "    return np.mean(y_preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ubiquant\n",
    "env = ubiquant.make_env()\n",
    "iter_test = env.iter_test() \n",
    "for (test_df, sample_prediction_df) in iter_test:\n",
    "    ds = make_test_dataset(test_df[features], test_df[\"investment_id\"])\n",
    "    sample_prediction_df['target'] = inference(models, ds)\n",
    "    env.predict(sample_prediction_df)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "204802287329ac0cf798540e345e8505329bf490b7b9371d7044f6322e5f6def"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 64-bit ('tw_tf': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
